{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Sentiment Analysis using Transformers with Distil Bert Multilingual Cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krupc\\Downloads\\Projects\\transformers\\03-sentiment-analysis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import transformers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! GPU name: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available! GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "(2000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am feeling completely overwhelmed i have two strategies that help me to feel grounded pour my heart out in my journal in the form of a letter to god and then end with a list of five things i am most grateful for</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have the feeling she was amused and delighted</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was able to help chai lifeline with your support and encouragement is a great feeling and i am so glad you were able to help me</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                    text  \\\n",
       "0  i am feeling completely overwhelmed i have two strategies that help me to feel grounded pour my heart out in my journal in the form of a letter to god and then end with a list of five things i am most grateful for   \n",
       "1                                                                                                                                                                        i have the feeling she was amused and delighted   \n",
       "2                                                                                      i was able to help chai lifeline with your support and encouragement is a great feeling and i am so glad you were able to help me   \n",
       "\n",
       "  feeling  \n",
       "0    fear  \n",
       "1     joy  \n",
       "2     joy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel like my only role now would be to tear your sails with my pessimism and discontent</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like reds and purples are just so rich and kind of perfect</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 text  \\\n",
       "0                           i feel like my only role now would be to tear your sails with my pessimism and discontent   \n",
       "1  i feel just bcoz a fight we get mad to each other n u wanna make a publicity n let the world knows about our fight   \n",
       "2                                                   i feel like reds and purples are just so rich and kind of perfect   \n",
       "\n",
       "   feeling  \n",
       "0  sadness  \n",
       "1    anger  \n",
       "2      joy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/train_data.txt', header=None, delimiter=';')\n",
    "df_test = pd.read_csv('data/test_data.txt', header=None, delimiter=';')\n",
    "\n",
    "df_train = df_train.rename(columns= {0: 'text', 1: 'feeling'})\n",
    "df_test = df_test.rename(columns= {0: 'text', 1: 'feeling'})\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "display(df_train.head(3))\n",
    "display(df_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feeling\n",
       "joy         5362\n",
       "sadness     4666\n",
       "anger       2159\n",
       "fear        1937\n",
       "love        1304\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['feeling'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feeling\n",
       "joy         695\n",
       "sadness     581\n",
       "anger       275\n",
       "fear        224\n",
       "love        159\n",
       "surprise     66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['feeling'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The column **text** will be the input feature and **feeling** will be the output target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\krupc\\downloads\\projects\\transformers\\03-sentiment-analysis\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\krupc\\downloads\\projects\\transformers\\03-sentiment-analysis\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\krupc\\downloads\\projects\\transformers\\03-sentiment-analysis\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\krupc\\downloads\\projects\\transformers\\03-sentiment-analysis\\.venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\krupc\\downloads\\projects\\transformers\\03-sentiment-analysis\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\krupc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\krupc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krupc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ensure required NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_nlp(text):\n",
    "    # Tokenize the text\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text.lower())  # Extract words, ignoring punctuation\n",
    "    # Remove stopwords, remove punctuation, and lemmatize\n",
    "    processed_tokens = [\n",
    "        lemmatizer.lemmatize(token.strip()) for token in tokens \n",
    "        if token not in stop_words and token.isalnum()  # Check for alphanumeric tokens\n",
    "    ]\n",
    "    # Join tokens into a single string\n",
    "    return ' '.join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['transformed_text_nltk'] = df_train['text'].apply(custom_nlp)\n",
    "df_test['transformed_text_nltk'] = df_test['text'].apply(custom_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>feeling</th>\n",
       "      <th>transformed_text_nltk</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i am feeling completely overwhelmed i have two strategies that help me to feel grounded pour my heart out in my journal in the form of a letter to god and then end with a list of five things i am most grateful for</td>\n",
       "      <td>fear</td>\n",
       "      <td>feeling completely overwhelmed two strategy help feel grounded pour heart journal form letter god end list five thing grateful</td>\n",
       "      <td>feel completely overwhelmed strategy help feel grounded pour heart journal form letter god end list thing grateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have the feeling she was amused and delighted</td>\n",
       "      <td>joy</td>\n",
       "      <td>feeling amused delighted</td>\n",
       "      <td>feeling amuse delight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i was able to help chai lifeline with your support and encouragement is a great feeling and i am so glad you were able to help me</td>\n",
       "      <td>joy</td>\n",
       "      <td>able help chai lifeline support encouragement great feeling glad able help</td>\n",
       "      <td>able help chai lifeline support encouragement great feeling glad able help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i already feel like i fucked up though because i dont usually eat at all in the morning</td>\n",
       "      <td>anger</td>\n",
       "      <td>already feel like fucked though dont usually eat morning</td>\n",
       "      <td>feel like fuck not usually eat morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i still love my so and wish the best for him i can no longer tolerate the effect that bm has on our lives and the fact that is has turned my so into a bitter angry person who is not always particularly kind to the people around him when he is feeling stressed</td>\n",
       "      <td>sadness</td>\n",
       "      <td>still love wish best longer tolerate effect bm life fact turned bitter angry person always particularly kind people around feeling stressed</td>\n",
       "      <td>love wish good long tolerate effect bm life fact turn bitter angry person particularly kind people feel stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag and i said to anna that i feel like i have been beaten up</td>\n",
       "      <td>sadness</td>\n",
       "      <td>brief time beanbag said anna feel like beaten</td>\n",
       "      <td>brief time beanbag say anna feel like beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am still waiting tables and subbing with a teaching degree</td>\n",
       "      <td>sadness</td>\n",
       "      <td>turning feel pathetic still waiting table subbing teaching degree</td>\n",
       "      <td>turn feel pathetic wait table sub teaching degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "      <td>feel strong good overall</td>\n",
       "      <td>feel strong good overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and im glad that t</td>\n",
       "      <td>anger</td>\n",
       "      <td>feel like rude comment im glad</td>\n",
       "      <td>feel like rude comment m glad t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i can not portray it</td>\n",
       "      <td>sadness</td>\n",
       "      <td>know lot feel stupid portray</td>\n",
       "      <td>know lot feel stupid portray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                    i am feeling completely overwhelmed i have two strategies that help me to feel grounded pour my heart out in my journal in the form of a letter to god and then end with a list of five things i am most grateful for   \n",
       "1                                                                                                                                                                                                                          i have the feeling she was amused and delighted   \n",
       "2                                                                                                                                        i was able to help chai lifeline with your support and encouragement is a great feeling and i am so glad you were able to help me   \n",
       "3                                                                                                                                                                                  i already feel like i fucked up though because i dont usually eat at all in the morning   \n",
       "4      i still love my so and wish the best for him i can no longer tolerate the effect that bm has on our lives and the fact that is has turned my so into a bitter angry person who is not always particularly kind to the people around him when he is feeling stressed   \n",
       "...                                                                                                                                                                                                                                                                    ...   \n",
       "15995                                                                                                                                                                i just had a very brief time in the beanbag and i said to anna that i feel like i have been beaten up   \n",
       "15996                                                                                                                                                               i am now turning and i feel pathetic that i am still waiting tables and subbing with a teaching degree   \n",
       "15997                                                                                                                                                                                                                                       i feel strong and good overall   \n",
       "15998                                                                                                                                                                                                          i feel like this was such a rude comment and im glad that t   \n",
       "15999                                                                                                                                                                                                       i know a lot but i feel so stupid because i can not portray it   \n",
       "\n",
       "       feeling  \\\n",
       "0         fear   \n",
       "1          joy   \n",
       "2          joy   \n",
       "3        anger   \n",
       "4      sadness   \n",
       "...        ...   \n",
       "15995  sadness   \n",
       "15996  sadness   \n",
       "15997      joy   \n",
       "15998    anger   \n",
       "15999  sadness   \n",
       "\n",
       "                                                                                                                             transformed_text_nltk  \\\n",
       "0                   feeling completely overwhelmed two strategy help feel grounded pour heart journal form letter god end list five thing grateful   \n",
       "1                                                                                                                         feeling amused delighted   \n",
       "2                                                                       able help chai lifeline support encouragement great feeling glad able help   \n",
       "3                                                                                         already feel like fucked though dont usually eat morning   \n",
       "4      still love wish best longer tolerate effect bm life fact turned bitter angry person always particularly kind people around feeling stressed   \n",
       "...                                                                                                                                            ...   \n",
       "15995                                                                                                brief time beanbag said anna feel like beaten   \n",
       "15996                                                                            turning feel pathetic still waiting table subbing teaching degree   \n",
       "15997                                                                                                                     feel strong good overall   \n",
       "15998                                                                                                               feel like rude comment im glad   \n",
       "15999                                                                                                                 know lot feel stupid portray   \n",
       "\n",
       "                                                                                                         transformed_text  \n",
       "0      feel completely overwhelmed strategy help feel grounded pour heart journal form letter god end list thing grateful  \n",
       "1                                                                                                   feeling amuse delight  \n",
       "2                                              able help chai lifeline support encouragement great feeling glad able help  \n",
       "3                                                                                  feel like fuck not usually eat morning  \n",
       "4          love wish good long tolerate effect bm life fact turn bitter angry person particularly kind people feel stress  \n",
       "...                                                                                                                   ...  \n",
       "15995                                                                          brief time beanbag say anna feel like beat  \n",
       "15996                                                                   turn feel pathetic wait table sub teaching degree  \n",
       "15997                                                                                            feel strong good overall  \n",
       "15998                                                                                     feel like rude comment m glad t  \n",
       "15999                                                                                        know lot feel stupid portray  \n",
       "\n",
       "[16000 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing using Spacy\n",
    "\n",
    "**Spacy** is an open-source library for advanced Natural Language Processing (NLP) in Python, designed specifically for production use with a focus on performance and ease of use. It provides fast and efficient processing, making it suitable for large datasets and real-time applications. The library includes pre-trained models for various languages, offering capabilities such as tokenization, part-of-speech tagging, named entity recognition, dependency parsing, lemmatization, and text classification. \n",
    "\n",
    "The user-friendly API allows you to implement complex NLP tasks with minimal code, and it integrates seamlessly with other libraries like TensorFlow and PyTorch. Additionally, spaCy supports the creation of custom pipelines and model training, ensuring flexibility for specific project needs. Its active community, comprehensive documentation, and ongoing development make it a reliable choice for anyone looking to incorporate robust NLP functionalities into their projects. Overall, spaCy is ideal for applications that require efficient text processing and analysis, making it a popular choice among data scientists and developers. [Oficial site](https://spacy.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dict\n",
    "spacy_nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the 'data_preprocessing' function that receives a text as a parameter\n",
    "def data_preprocessing(text):\n",
    "\n",
    "    # Process the text using the dictionary\n",
    "    doc = spacy_nlp(text)\n",
    "\n",
    "    # Creates a list of lemmas from the tokens, converted to lowercase and without whitespace,\n",
    "    # excluding words that are stopwords\n",
    "    tokens = [token.lemma_.lower().strip() for token in doc if not token.is_stop]\n",
    "\n",
    "    # Returns the processed tokens as a single string, joining them with spaces\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['transformed_text'] = df_train['text'].apply(data_preprocessing)\n",
    "df_test['transformed_text'] = df_test['text'].apply(data_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Platform\n",
    "\n",
    "Hugging Face is a prominent AI research organization and platform that focuses on natural language processing (NLP) and machine learning. It is best known for its user-friendly libraries and tools that facilitate the development, training, and deployment of state-of-the-art machine learning models, particularly those based on transformer architectures. Here are some key aspects of the Hugging Face platform:\n",
    "\n",
    "**Key Features**\n",
    "\n",
    "1. **Transformers Library**:\n",
    "   - The `Transformers` library provides access to a wide variety of pre-trained models for NLP tasks, such as text classification, translation, summarization, and named entity recognition. The library supports models like BERT, GPT-2, RoBERTa, T5, and many more.\n",
    "\n",
    "2. **Datasets Library**:\n",
    "   - Hugging Face offers the `Datasets` library, which provides easy access to a large collection of datasets for machine learning tasks. This library simplifies loading, processing, and sharing datasets across various projects.\n",
    "\n",
    "3. **Tokenizers Library**:\n",
    "   - The `Tokenizers` library is designed for efficient tokenization, providing tools to preprocess text data for various NLP tasks. It supports multiple tokenization algorithms, including Byte Pair Encoding (BPE) and WordPiece.\n",
    "\n",
    "4. **Model Hub**:\n",
    "   - Hugging Face hosts a Model Hub where users can find, share, and use thousands of pre-trained models contributed by the community and organizations. Users can easily download and integrate these models into their applications.\n",
    "\n",
    "5. **Training and Fine-tuning**:\n",
    "   - The platform provides straightforward APIs for training and fine-tuning models on custom datasets, making it accessible even for those who may not have extensive experience in machine learning.\n",
    "\n",
    "6. **Infrastructural Support**:\n",
    "   - Hugging Face offers tools like `Trainer` and `Pipeline` that simplify the process of model training, evaluation, and inference, reducing the complexity of setting up and managing experiments.\n",
    "\n",
    "7. **Community and Collaboration**:\n",
    "   - The Hugging Face community is active and supportive, offering forums, documentation, and tutorials to help users get started with machine learning and NLP.\n",
    "\n",
    "8. **Integration with Other Frameworks**:\n",
    "   - Hugging Face’s libraries can easily be integrated with popular deep learning frameworks like TensorFlow and PyTorch, allowing users to leverage the strengths of both ecosystems.\n",
    "\n",
    "**Why Use Hugging Face?**\n",
    "\n",
    "- **Accessibility**: The user-friendly APIs and extensive documentation make it easy for both beginners and experienced practitioners to work with advanced NLP models.\n",
    "- **Cutting-edge Models**: Hugging Face keeps its model library updated with the latest advancements in NLP, allowing users to experiment with state-of-the-art techniques.\n",
    "- **Community-driven**: The collaborative nature of Hugging Face encourages sharing and learning, making it a rich resource for researchers and developers alike.\n",
    "- **Rapid Development**: With pre-trained models and streamlined tools, Hugging Face accelerates the development process for NLP applications, reducing time-to-market.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Overall, Hugging Face has established itself as a leading platform in the field of NLP and machine learning, providing powerful tools and resources that empower developers and researchers to create innovative AI applications. Whether you are working on a research project, a commercial application, or simply exploring NLP, Hugging Face offers the tools to help you succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning of Pre-Trained Transformer Model using DistilBERT Base Multilingual Cased\n",
    "\n",
    "We will use the data processed with SpaCy and then perform the specific processing for the BERT model, just as we did with the model in version 1.\n",
    "\n",
    "DistilBERT Base Multilingual Cased is a transformer-based language model developed by Hugging Face that is designed for multilingual natural language processing tasks. It is a distilled version of the BERT (Bidirectional Encoder Representations from Transformers) model, optimized to be smaller, faster, and more efficient while retaining a significant portion of BERT's performance. \n",
    "\n",
    "This model is trained on multiple languages, allowing it to handle over 100 languages, including English, Spanish, French, and German. The \"cased\" designation means that the model distinguishes between uppercase and lowercase letters, which is important for languages where case sensitivity matters.\n",
    "\n",
    "DistilBERT Base Multilingual Cased can be used for various NLP tasks such as text classification, named entity recognition, question answering, and sentiment analysis. It is approximately 60% smaller than BERT but retains about 97% of its performance on language understanding tasks, making it an attractive option for developers seeking efficient models without sacrificing accuracy. The model can be easily integrated into applications using the Hugging Face Transformers library, providing a versatile tool for multilingual text processing.\n",
    "\n",
    "https://huggingface.co/distilbert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the text into a sequence of integers for input to the BERT model\n",
    "def encode(texts, tokenizer, chunk_size = 256, max_len = 512):\n",
    "\n",
    "    # Enable truncation in the tokenizer to a specified max length\n",
    "    tokenizer.enable_truncation(max_length = max_len)\n",
    "\n",
    "    # Enable padding in th tokenizer to a specified max length\n",
    "    tokenizer.enable_padding(length = max_len)\n",
    "\n",
    "    # Initialize a list to stor the encoded IDs\n",
    "    all_ids = []\n",
    "\n",
    "    # Iterate over texts in chunk of size 'chunk_size'\n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "\n",
    "        # Create a chunk of text\n",
    "        text_chunk = texts[i:i+chunk_size].tolist()\n",
    "\n",
    "        # Encode the chunk of text in batch\n",
    "        encs = tokenizer.encode_batch(text_chunk)\n",
    "\n",
    "        # Extend the list 'all_ids' with the encoded IDs\n",
    "        all_ids.extend([enc.ids for enc in encs])\n",
    "\n",
    "    # Return the IDs list as an array numpy\n",
    "    return np.array(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer from the pretrained model \n",
    "tokenizer_bert = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "\n",
    "# Save the tokenizer and the vocabulary locally\n",
    "tokenizer_bert.save_pretrained('.')\n",
    "\n",
    "# Load a faster tokenizer using the vocabulary of main tokenizer \n",
    "fast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase = False)\n",
    "\n",
    "# Show the tokenizer\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_train['transformed_text'].values,\n",
    "                                                        df_train['feeling'].values,\n",
    "                                                        test_size = 0.2,\n",
    "                                                        random_state = 42,\n",
    "                                                        stratify = df_train['feeling'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified sampling is a technique used in statistics to ensure that subgroups (or strata) of a population are adequately represented within a sample. It is particularly useful in situations where the population is heterogeneous and the subgroups have different characteristics that are important to the research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max lenght used in the text\n",
    "max_length = 100\n",
    "\n",
    "# Applying the encode in our data, using the faster tokenizer\n",
    "X_final_train = encode(X_train, fast_tokenizer, max_len = max_length)\n",
    "X_final_valid = encode(X_valid, fast_tokenizer, max_len = max_length)\n",
    "X_final_test = encode(df_test['transformed_text'].to_numpy(), fast_tokenizer, max_len = max_length)\n",
    "\n",
    "X_final_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    # Converts y into an array of numpy\n",
    "    y = np.array(y, dtype='int')\n",
    "    \n",
    "    # If the number of classes is not given, it will be determined from y\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    \n",
    "    # Initialize the output array with zeros\n",
    "    categorical = np.zeros((y.shape[0], num_classes), dtype=dtype)\n",
    "    \n",
    "    # Fill the matrix with 1 in the position corresponding to the class of each label\n",
    "    categorical[np.arange(y.shape[0]), y] = 1\n",
    "    \n",
    "    return categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder of output data\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Applying the label encoder (fit_transform only on train data)\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_valid_le = le.transform(y_valid)\n",
    "y_test_le = le.transform(df_test['feeling'])\n",
    "\n",
    "# Convert the output variable to categorical\n",
    "y_train_encoded = to_categorical(y_train_le)\n",
    "y_valid_encoded = to_categorical(y_valid_le)\n",
    "y_test_encoded = to_categorical(y_test_le)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data preprocessing for Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prepares datasets for training, validation, and testing using PyTorch’s `DataLoader` and a pre-trained multilingual DistilBERT model. Here's a breakdown of each part:\n",
    "\n",
    "1. **Batch Size Setting**\n",
    "   The batch size for model training and evaluation is set to 16, meaning the model will process data in groups of 16 samples at a time.\n",
    "\n",
    "2. **Preparing the Training Dataset and DataLoader**\n",
    "   - `TensorDataset` is used to create a PyTorch dataset from the training features (`X_final_train`) and training labels (`y_train_encoded`). Both `X_final_train` and `y_train_encoded` are converted to tensors for compatibility with PyTorch.\n",
    "   - `DataLoader` wraps the `train_dataset`, allowing it to be loaded in batches. The `shuffle=True` argument shuffles the data at the start of each epoch, which helps improve training by reducing overfitting.\n",
    "\n",
    "3. **Preparing the Validation Dataset and DataLoader**\n",
    "   - This section creates a validation dataset and loader in the same way as the training data, but without shuffling (`shuffle=False`). The `valid_loader` will be used to evaluate model performance after each training epoch.\n",
    "\n",
    "4. **Preparing the Test Dataset and DataLoader**\n",
    "   - Similar to the training loader, this code prepares the test dataset and loader with shuffling enabled. The `test_loader` will allow for evaluation on the test set after training completes.\n",
    "\n",
    "5. **Loading the Pre-Trained DistilBERT Model**\n",
    "   - Here, an instance of the `DistilBertModel` is created using the pre-trained multilingual version (`distilbert-base-multilingual-cased`) from Hugging Face. This model will be further fine-tuned on the specific task defined by the prepared datasets.\n",
    "\n",
    "This code structure allows efficient training, validation, and testing of a model, while the pre-trained DistilBERT model provides a strong starting point for handling multilingual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Prepare the dataset in the expected format of Pytorch\n",
    "train_dataset = TensorDataset(torch.tensor(X_final_train), torch.tensor(y_train_encoded))\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(torch.tensor(X_final_valid), torch.tensor(y_valid_encoded))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(X_final_test), torch.tensor(y_test_encoded))\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Creates an instance of the pre-trained, multilingual DistilBERT model suitable for use with PyTorch\n",
    "transformer_model = DistilBertModel.from_pretrained('distilbert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Pytorch model\n",
    "\n",
    "This code defines a custom PyTorch model class `Model` that uses a pre-trained transformer model (like DistilBERT) as its base and adds a classification layer to output predictions. Here's a breakdown of each part:\n",
    "\n",
    "1. **Class Definition and Initialization**\n",
    "   - The `Model` class inherits from `nn.Module`, the base class for all neural network modules in PyTorch.\n",
    "   - The `__init__` method initializes the model, accepting a pre-trained transformer (like DistilBERT) and setting `num_labels` as the number of output classes (in this case, 6).\n",
    "   - The `transformer` layer stores the pre-trained transformer model for feature extraction.\n",
    "   - The `classifier` layer is a fully connected (dense) layer that takes the transformer model's output size (`hidden_size`) and maps it to the number of classes specified by `num_labels`.\n",
    "   - The `softmax` layer applies the softmax function along dimension 1 (the class dimension), converting the raw scores (logits) from the classifier into probabilities.\n",
    "\n",
    "2. **Forward Pass**\n",
    "   - The `forward` method defines the forward pass, taking `input_ids` as input (these are tokenized text sequences).\n",
    "   - `self.transformer(input_ids)` passes the input sequences through the transformer, producing the `last_hidden_state` for each token in each sequence.\n",
    "   - The code then selects the first token embedding from `sequence_output` (often representing the `[CLS]` token in BERT-based models), which typically contains the aggregate information for the sequence.\n",
    "\n",
    "3. **Classification and Output**\n",
    "   - `self.classifier(cls_token)` passes the `[CLS]` token embedding through the classifier layer, producing raw scores (logits) for each class.\n",
    "   - `self.softmax(logits)` converts these logits into probabilities across the classes.\n",
    "   - The final output `out` contains probabilities for each class, allowing the model to make a classification prediction.\n",
    "\n",
    "In summary, this code defines a model that uses a transformer to process input text and applies a dense layer with a softmax activation to classify the text into one of the six specified classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, transformer, num_labels = 6):\n",
    "        super(Model, self).__init__()\n",
    "        self.transformer = transformer\n",
    "        self.classifier = nn.Linear(transformer.config.hidden_size, num_labels)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Getting the output of sequence of transformer\n",
    "        outputs = self.transformer(input_ids)\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        \n",
    "        # Selecting the fist token of each sequence (token CLS from BERT) to classification\n",
    "        cls_token = sequence_output[:, 0, :]\n",
    "\n",
    "        # Adding a dense layer to the output with softmax activation for classification\n",
    "        logits = self.classifier(cls_token)\n",
    "        out = self.softmax(logits)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters\n",
    "\n",
    "This code initializes the custom `Model` class with a pre-trained transformer, selectively freezes some of the transformer's parameters, sets up the optimizer and loss function, and prints a summary of the model structure. Here’s a breakdown:\n",
    "\n",
    "1. **Model Initialization**\n",
    "   - An instance of the `Model` class is created, with `transformer_model` (e.g., DistilBERT) passed as the `transformer` parameter.\n",
    "   - This wraps the pre-trained transformer in the custom model, which includes additional layers for classification.\n",
    "\n",
    "2. **Freezing Transformer Parameters**\n",
    "   - The loop iterates over the first three parameters of the `transformer` within the `model`, setting `requires_grad` to `False`.\n",
    "   - Setting `requires_grad = False` prevents these parameters from being updated during training, effectively \"freezing\" them. This can be useful when using transfer learning to retain some of the pre-trained transformer weights while reducing the computational load.\n",
    "\n",
    "3. **Defining the Optimizer and Loss Function**\n",
    "   - The `optimizer` is set to Adam, a commonly used optimization algorithm for training neural networks. The learning rate (`lr`) is set to \\(1 \\times 10^{-5}\\), which is often appropriate for fine-tuning a pre-trained transformer.\n",
    "   - The `criterion` or loss function is set to `CrossEntropyLoss`, which is commonly used for multi-class classification tasks. It calculates the difference between the predicted and actual class labels and helps guide the model to improve predictions during training.\n",
    "\n",
    "4. **Printing Model Summary**\n",
    "   - This line prints a summary of the model architecture, including the layers within the `Model` class and the pre-trained transformer. This summary provides insights into the model’s structure, parameters, and number of layers, which can help in debugging and verifying the model setup.\n",
    "\n",
    "In summary, this code sets up the model for transfer learning by partially freezing the transformer parameters, defining the optimizer and loss function for training, and printing a summary to verify the model’s configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(transformer=transformer_model)\n",
    "\n",
    "for param in list(model.transformer.parameters())[:3]:\n",
    "    param.requires_grad = False \n",
    "\n",
    "# Defines the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "This code trains a PyTorch model over multiple epochs using GPU acceleration (if available) and evaluates it on a validation dataset after each epoch. It tracks training and validation losses, along with metrics like accuracy and precision. Here’s a step-by-step explanation:\n",
    "\n",
    "1. **Epoch Setup and Device Configuration**\n",
    "   - The number of epochs is set to 10.\n",
    "   - `train_losses` and `val_losses` lists store the average loss for each epoch in training and validation.\n",
    "   - The `device` is set to GPU (`cuda`) if available; otherwise, it defaults to CPU.\n",
    "   - The model is moved to the chosen device.\n",
    "\n",
    "2. **Training Loop**\n",
    "   - The loop iterates over each epoch, setting the model to training mode with `model.train()`.\n",
    "   - `running_loss` keeps track of the cumulative loss within each epoch.\n",
    "   - `train_loader_tqdm` uses `tqdm` to display a progress bar for each epoch.\n",
    "\n",
    "3. **Batch Processing and Backpropagation**\n",
    "   - Each batch of input data (`input_ids` and `labels`) is moved to the appropriate device.\n",
    "   - `optimizer.zero_grad()` resets gradients to prevent accumulation.\n",
    "   - The model computes predictions (`outputs`), and the loss is calculated using `criterion`.\n",
    "   - `loss.backward()` performs backpropagation to compute gradients, followed by `optimizer.step()` to update the model weights.\n",
    "   - `running_loss` accumulates the batch loss to calculate the epoch’s average loss.\n",
    "\n",
    "4. **Prediction and Tracking Loss**\n",
    "   - `preds` represents the predicted class indices, obtained by taking the `argmax` of `outputs` along the class dimension.\n",
    "   - Predictions are stored on the CPU for further analysis.\n",
    "   - The progress bar updates with the current batch loss.\n",
    "\n",
    "5. **Epoch-Level Training Loss Calculation**\n",
    "   - The average loss for the epoch is calculated by dividing `running_loss` by the number of batches (`len(train_loader)`).\n",
    "   - `train_loss` is stored for tracking training progress.\n",
    "\n",
    "6. **Validation Loop**\n",
    "   - The model is set to evaluation mode (`model.eval()`), and gradient computation is disabled (`torch.no_grad()`).\n",
    "   - Similar to training, each batch is passed through the model to calculate predictions and the validation loss.\n",
    "   - `val_running_loss` accumulates the loss across validation batches.\n",
    "\n",
    "7. **Validation Predictions and Metrics Calculation**\n",
    "   - `val_labels` and `val_preds` are obtained by taking the `argmax` of `labels` and `outputs`.\n",
    "   - Predictions and actual labels are stored for accuracy and precision calculation.\n",
    "\n",
    "8. **Calculating and Printing Metrics**\n",
    "   - `val_loss_avg` calculates the average validation loss.\n",
    "   - `val_accuracy` and `val_precision` compute accuracy and weighted precision on the validation set using the stored predictions and labels.\n",
    "   - Each epoch’s metrics are printed to track the model’s training and validation progress. \n",
    "\n",
    "This code provides an efficient way to train and evaluate the model, enabling tracking of key performance metrics across multiple epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Move the model to GPU\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Progress_bar\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f'Training - Epoch {epoch+1}/{num_epochs}')\n",
    "\n",
    "    for batch in train_loader_tqdm:\n",
    "        input_ids, labels = batch\n",
    "        # Move to GPU\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Converting predictions to classes (index)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # Store predictions and labels\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        # Update progress bar with current average loss\n",
    "        train_loader_tqdm.set_postfix({'Loss (batch)': loss.item()})\n",
    "\n",
    "    # Average loss in training\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    all_val_preds = []\n",
    "    all_val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            input_ids, labels = batch\n",
    "            # Move to GPU\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(input_ids)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "\n",
    "            # Converting predictions to classes (index)\n",
    "            val_labels = torch.argmax(labels, dim=1)\n",
    "            val_preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # Store predictions and labels\n",
    "            all_val_preds.extend(val_preds.cpu().numpy())\n",
    "            all_val_labels.extend(val_labels.cpu().numpy())\n",
    "    # \n",
    "    val_loss_avg = val_running_loss / len(valid_loader)\n",
    "    val_losses.append(val_loss_avg)\n",
    "\n",
    "    # Calculate validation metrics  \n",
    "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average='weighted')\n",
    "\n",
    "    # Print metrics after each epoch\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Loss of Training: {train_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training Error')\n",
    "plt.plot(val_losses, label='Validation Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "model.eval()\n",
    "\n",
    "# Converting X_final_test to a PyTorch tensor\n",
    "X_test_final_tensor = torch.tensor(X_final_test).to(device)\n",
    "\n",
    "# Predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_final_tensor)\n",
    "\n",
    "# Predicted labels (choosing the class index with highest probability)\n",
    "predicted_labels = torch.argmax(predictions, dim=1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_le, predicted_labels))\n",
    "\n",
    "print(confusion_matrix(y_test_le, predicted_labels))\n",
    "\n",
    "print(accuracy_score(y_test_le, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving only weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saving\n",
    "# Path where the model will be saved\n",
    "PATH = \"models/model_v3.pth\"\n",
    "\n",
    "# Saving only model weights\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "## Loading\n",
    "# Initializing the model (architecture must be the same as the saved model)\n",
    "model = Model(transformer_model)\n",
    "\n",
    "# Loaded the saved weights \n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Put the model in evaluation mode if it is for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"models/model_v3_complete.pth\")\n",
    "\n",
    "# Loading the complete model\n",
    "model = torch.load(\"models/model_v3_complete.pth\")\n",
    "\n",
    "# Putting the model in evaluation mode if it is for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New sentence\n",
    "sentence = \"I'm happy today\"\n",
    "\n",
    "# Create a dataframe with the sentence\n",
    "df_new = pd.DataFrame({'text': [sentence]})\n",
    "\n",
    "# Applying the preprocessing function\n",
    "df_new['transformed_text'] = df_new['text'].apply(data_preprocessing)\n",
    "\n",
    "new_data = encode(df_new['transformed_text'], fast_tokenizer, max_len = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting new_data to a PyTorch tensor if it isn't already\n",
    "new_data_tensor = torch.tensor(new_data).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Prediction\n",
    "with torch.no_grad():\n",
    "    prediction = model(new_data_tensor)\n",
    "\n",
    "# Predicted labels (choosing the class index with highest probability)\n",
    "predicted_label = torch.argmax(prediction, dim=1).cpu().numpy()\n",
    "\n",
    "# Get the class name\n",
    "class_name = le.inverse_transform(predicted_label)\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Releases any unused memory held by PyTorch’s CUDA memory allocator.\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
