{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attencion Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the article [A Deep Dive into Transformers Architecture](https://medium.com/@krupck/a-deep-dive-into-transformers-architecture-58fed326b08d), I explained in detail all the theory behind the architecture and mechanisms of transformers, covering everything from the mathematical foundations to the nuances that make this model so powerful and versatile. Now it’s time to turn theory into practice! Let’s roll up our sleeves and implement the attention layer, diving into how each component interacts to solidify our knowledge and gain a deeper understanding of the inner workings of these models that have revolutionized the field of artificial intelligence. This hands-on step will be essential to reinforce the concepts learned and pave the way for building real-world applications based on transformers.\n",
    "\n",
    "We’ll create a model capable of predicting sequences with a length of 10 tokens.\n",
    "\n",
    "A Transformer model consists of several key components:\n",
    "1. **Embedding Layer**: Transforms words into fixed-size numerical vectors.  \n",
    "2. **Attention Mechanism**: Allows the model to focus on different parts of the input.  \n",
    "3. **Encoder and Decoder Layers**: Process data sequentially.  \n",
    "4. **Linear and Softmax Layers**: Perform the final predictions.  \n",
    "\n",
    "For this project, the main objective is to implement item 2. However, to make the example functional, I will also implement items 1 and 4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Layer  \n",
    "\n",
    "The embedding function is used to convert sequential inputs into dense, fixed-size vectors. These vectors, known as embeddings, are a fundamental part of natural language processing (NLP) models.  \n",
    "\n",
    "Embeddings are crucial for deep learning models in NLP as they provide a rich and dense representation of words or tokens, capturing contextual and semantic information essential for tasks like machine translation, text classification, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create an embedding matrix\n",
    "def embedding(input, vocab_size, dim_model):\n",
    "\n",
    "    # Creates an embedding matrix where each row represents a token in the vocabulary. \n",
    "    # The matrix is initialized with randomly distributed values.\n",
    "    embed = np.random.randn(vocab_size, dim_model)\n",
    "\n",
    "    # For each token index in the input, the corresponding embedding is selected from the matrix.\n",
    "    # Returns an array of embeddings corresponding to the input sequence.\n",
    "    return np.array([embed[i] for i in input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mechanism  \n",
    "\n",
    "In the Transformer, **Q** (Query), **K** (Key), and **V** (Value) are derived from the same input in the encoder’s attention layers but come from different inputs in the decoder (Q comes from the decoder’s previous layer output, while K and V come from the encoder’s output).  \n",
    "\n",
    "The attention mechanism computes a set of scores (using the dot product between Q and K, hence the name \"scaled dot-product attention\"), applies a softmax function to obtain attention weights, and uses these weights to scale the values (V). This produces an output that is a weighted combination of the relevant input information.  \n",
    "\n",
    "This process allows the model to \"pay attention\" to the most relevant parts of the input for each part of the output, which is especially useful for tasks like translation, where the relevance of different input words can vary depending on the part of the sentence being translated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Activation Function\n",
    "\n",
    "The softmax function is a widely used activation function in neural networks, especially in classification scenarios where it is important to transform raw output values (logits) into probabilities that sum to 1. Below is the code for the softmax function, with comments on each line explaining its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax Activation Function\n",
    "def softmax(x):\n",
    "    # Compute the exponential of each element in the input, adjusted by the maximum value in the input\n",
    "    # to prevent numerical overflow\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    \n",
    "    # Divide each exponential by the sum of exponentials along the last axis (axis=-1)\n",
    "    # The reshape(-1, 1) ensures proper division in a multidimensional context\n",
    "    return e_x / e_x.sum(axis=-1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled Dot Product\n",
    "\n",
    "The `scaled_dot_product_attention()` function is a component of the attention mechanism in Transformer models. It calculates the attention between sets of queries (Q), keys (K), and values (V).  \n",
    "\n",
    "Essentially, this function enables the model to assign different levels of importance to various parts of the input, a key aspect that makes Transformer models particularly effective for NLP tasks and other sequential problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to calculate scaled dot-product attention\n",
    "def scaled_dot_product_attention(Q, K, V):\n",
    "    # Compute the dot product between Q and the transpose of K\n",
    "    matmul_qk = np.dot(Q, K.T)\n",
    "    \n",
    "    # Get the dimension of the key vectors\n",
    "    depth = K.shape[-1]\n",
    "    \n",
    "    # Scale the logits by dividing by the square root of the depth\n",
    "    logits = matmul_qk / np.sqrt(depth)\n",
    "    \n",
    "    # Apply the softmax function to get the attention weights\n",
    "    attention_weights = softmax(logits)\n",
    "    \n",
    "    # Multiply the attention weights by the values V to get the final output\n",
    "    output = np.dot(attention_weights, V)\n",
    "    \n",
    "    # Return the weighted output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Output with Linear Operation and Softmax\n",
    "\n",
    "The `linear_and_softmax()` function combines a linear layer followed by a softmax function, commonly used in deep learning models, especially for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that applies a linear transformation followed by softmax\n",
    "def linear_and_softmax(input):\n",
    "    # Initialize a weight matrix with randomly distributed values\n",
    "    # This matrix connects each model dimension (dim_model) to each vocabulary word (vocab_size)\n",
    "    weights = np.random.randn(dim_model, vocab_size)\n",
    "    \n",
    "    # Perform the linear operation (dot product) between the input and the weight matrix\n",
    "    # The result, logits, is a vector representing the input transformed into a higher-dimensional space\n",
    "    logits = np.dot(input, weights)\n",
    "    \n",
    "    # Apply the softmax function to the logits\n",
    "    # This transforms the logits into a probability vector, where the elements sum to 1\n",
    "    return softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model function\n",
    "def transformer_model(input):\n",
    "    # Embedding\n",
    "    embedded_input = embedding(input, vocab_size, dim_model)\n",
    "    \n",
    "    # Attention Mechanism\n",
    "    attention_output = scaled_dot_product_attention(embedded_input, embedded_input, embedded_input)\n",
    "    \n",
    "    # Linear layer and softmax\n",
    "    output_probabilities = linear_and_softmax(attention_output)\n",
    "    \n",
    "    # Choose the indices with the highest probability\n",
    "    output_indices = np.argmax(output_probabilities, axis=-1)\n",
    "    \n",
    "    return output_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Initial Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model dimension\n",
    "dim_model = 4\n",
    "\n",
    "# Sequence length\n",
    "seq_length = 5\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Using the Model for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: [28 59 35 80 14]\n",
      "Model Output: [29 29 81 29 29]\n"
     ]
    }
   ],
   "source": [
    "# Generating random data for the model input\n",
    "input_sequence = np.random.randint(0, vocab_size, seq_length)\n",
    "print(\"Input Sequence:\", input_sequence)\n",
    "\n",
    "# Making predictions with the model\n",
    "output = transformer_model(input_sequence)\n",
    "print(\"Model Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61, 27, 89, 75, 13])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating random data for the model input\n",
    "input_sequence = np.random.randint(0, vocab_size, seq_length)\n",
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.45603545,  1.01156137,  1.2830995 , -0.90838249]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding\n",
    "embedded_input = embedding(input_sequence, vocab_size, dim_model)\n",
    "embedded_input[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.28904947,  0.89450866,  1.00997079, -0.42816149],\n",
       "       [ 0.6436809 , -1.64215604, -0.72219075,  0.07433874],\n",
       "       [ 0.87272191,  0.63963007,  0.23511223,  1.33028821],\n",
       "       [ 0.92727302,  0.54858306,  0.34207077,  0.78671392],\n",
       "       [ 0.59935589,  0.99040885,  0.22946714,  1.15830619]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attention Mechanism\n",
    "attention_output = scaled_dot_product_attention(embedded_input, embedded_input, embedded_input)\n",
    "attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.38738600e-04, 1.69069844e-02, 7.51233476e-04, 3.64708815e-04,\n",
       "        9.43103740e-04, 5.62525975e-04, 6.81753218e-04, 8.96685434e-04,\n",
       "        2.45220271e-03, 4.20546520e-04, 1.55358292e-04, 2.00917670e-03,\n",
       "        5.32383013e-05, 1.20201745e-04, 9.77862415e-03, 2.94847080e-04,\n",
       "        3.04520184e-03, 9.03622368e-04, 7.11965073e-04, 1.00718321e-03,\n",
       "        7.94099593e-02, 1.50927796e-03, 1.48418340e-02, 1.81402415e-03,\n",
       "        4.56680418e-04, 2.53146550e-03, 1.78300070e-03, 1.06983862e-02,\n",
       "        1.38337568e-05, 1.30624459e-04, 1.12358496e-03, 1.36139662e-03,\n",
       "        1.70383111e-03, 5.68688783e-03, 6.40813610e-03, 1.76048073e-03,\n",
       "        8.53477153e-03, 2.27582194e-05, 1.80740720e-01, 1.58274873e-02,\n",
       "        1.17145903e-04, 3.73107067e-04, 2.62458863e-03, 2.73960809e-04,\n",
       "        6.05706288e-05, 1.10463185e-03, 2.70273205e-03, 4.27700223e-04,\n",
       "        2.02133877e-04, 5.54596546e-04, 6.38692649e-04, 3.38231589e-04,\n",
       "        1.25578118e-04, 1.42738402e-04, 4.16319225e-04, 8.56440610e-03,\n",
       "        7.81595332e-03, 2.79917883e-04, 1.13023436e-03, 4.40508832e-02,\n",
       "        1.56167982e-05, 1.26419547e-04, 5.54228993e-04, 5.43751201e-05,\n",
       "        1.25316583e-03, 4.69998466e-04, 4.20443848e-03, 4.77498139e-04,\n",
       "        3.28742972e-03, 5.71340547e-05, 1.84524430e-04, 2.29812386e-03,\n",
       "        5.96741518e-03, 6.07020382e-04, 7.34423974e-06, 3.64375592e-02,\n",
       "        5.23194497e-04, 5.20910454e-05, 1.06523843e-02, 1.78172991e-04,\n",
       "        2.26519528e-05, 3.94203574e-03, 4.11454209e-03, 1.17811693e-03,\n",
       "        2.40999485e-01, 7.93559337e-05, 3.71027199e-05, 2.89669504e-03,\n",
       "        5.99163417e-04, 5.91631426e-05, 4.13859298e-02, 1.70054798e-02,\n",
       "        2.70704370e-02, 2.51011602e-04, 4.06185331e-04, 1.38207915e-01,\n",
       "        2.69713373e-04, 8.69746614e-04, 1.38610741e-03, 5.09861998e-04],\n",
       "       [3.16626343e-03, 8.82184714e-04, 4.00933928e-03, 4.43920431e-03,\n",
       "        5.94827583e-03, 3.09025814e-03, 2.18422530e-03, 1.15395656e-05,\n",
       "        1.35625713e-03, 3.20772810e-04, 1.16975849e-02, 4.05082361e-03,\n",
       "        9.73640260e-04, 8.09813392e-03, 1.96719115e-02, 4.74966225e-03,\n",
       "        1.00211864e-02, 6.53768826e-03, 1.03154789e-03, 1.70491450e-03,\n",
       "        4.01031850e-04, 1.05176273e-03, 6.82442824e-03, 4.14217743e-03,\n",
       "        6.41330911e-03, 1.25054977e-02, 1.28722193e-02, 2.46109983e-03,\n",
       "        1.79049142e-03, 1.80291335e-01, 5.28274747e-02, 2.33512202e-03,\n",
       "        1.06408127e-02, 4.23919647e-04, 4.32406892e-03, 1.28215047e-03,\n",
       "        3.53980499e-03, 6.77515457e-03, 6.94201687e-05, 2.65925688e-05,\n",
       "        3.18383703e-03, 8.95381541e-04, 6.68884157e-04, 9.64909826e-03,\n",
       "        1.21000194e-02, 1.56298175e-03, 2.43971492e-03, 1.03515479e-03,\n",
       "        3.82896369e-02, 3.83303233e-04, 3.35382681e-03, 1.11419965e-02,\n",
       "        2.26096532e-02, 4.79386528e-02, 1.50359656e-02, 4.54384577e-02,\n",
       "        1.22597161e-03, 1.87038729e-03, 2.00169122e-02, 9.42164442e-03,\n",
       "        3.82930644e-03, 5.20974232e-03, 1.85810155e-03, 1.37910778e-02,\n",
       "        3.30891984e-04, 2.62896585e-02, 2.77167761e-04, 6.84520766e-03,\n",
       "        1.27608909e-03, 1.77680121e-02, 2.62100361e-03, 6.27479570e-04,\n",
       "        1.38515735e-05, 5.91701245e-03, 1.92544313e-03, 4.30994267e-04,\n",
       "        5.61931434e-03, 1.03318827e-02, 2.93819810e-04, 1.81500839e-03,\n",
       "        5.39009647e-03, 2.05044910e-03, 1.66151664e-02, 6.95799578e-03,\n",
       "        1.89358343e-05, 1.32570935e-02, 2.39676841e-02, 2.91271230e-03,\n",
       "        3.27199873e-03, 2.64733094e-02, 1.52151927e-05, 9.11473294e-03,\n",
       "        6.60012639e-03, 2.67496135e-03, 7.63980338e-03, 6.63664416e-04,\n",
       "        2.67775098e-02, 1.04174732e-04, 9.24869961e-04, 8.42936673e-02],\n",
       "       [7.79113971e-03, 3.13365793e-02, 1.61762589e-04, 9.42287509e-04,\n",
       "        6.52185380e-03, 1.53099911e-02, 9.13708207e-03, 2.96427237e-03,\n",
       "        3.42069557e-03, 1.20911834e-03, 1.13669470e-03, 9.10159149e-04,\n",
       "        1.25774735e-03, 1.92132856e-02, 3.23000855e-02, 2.76230982e-04,\n",
       "        1.09934137e-02, 4.24285052e-03, 1.27361220e-04, 2.05699076e-03,\n",
       "        3.28717554e-03, 5.16076964e-03, 1.23095373e-02, 1.81508284e-03,\n",
       "        8.45292735e-03, 5.52043932e-02, 1.97393054e-03, 3.57616247e-03,\n",
       "        7.77653660e-04, 2.51008448e-04, 2.60135645e-02, 6.13489313e-04,\n",
       "        2.84259209e-04, 1.53126470e-02, 1.45137627e-02, 8.04759511e-03,\n",
       "        4.22022084e-03, 1.51316258e-03, 1.85357001e-03, 7.93765729e-03,\n",
       "        4.85870822e-04, 1.94329165e-03, 1.16554728e-03, 1.15684621e-02,\n",
       "        1.68312270e-03, 5.93334844e-04, 1.52941894e-03, 5.25031333e-04,\n",
       "        3.01314879e-04, 1.30142586e-04, 1.64876984e-03, 1.64802415e-02,\n",
       "        4.45888356e-03, 3.78853824e-03, 3.16735617e-03, 1.37215699e-02,\n",
       "        8.14986804e-03, 2.83105400e-04, 7.53162535e-04, 2.79730923e-02,\n",
       "        1.43737533e-03, 6.94715313e-03, 6.51185737e-03, 1.21480562e-03,\n",
       "        6.66062754e-03, 3.31110183e-03, 1.02384114e-02, 4.30695435e-03,\n",
       "        1.03682033e-04, 7.84389860e-06, 5.63663905e-04, 1.54418506e-02,\n",
       "        3.09226396e-02, 1.99706939e-03, 2.68824177e-04, 1.38802382e-02,\n",
       "        2.70988131e-03, 1.09100728e-03, 2.32150075e-03, 3.45199373e-03,\n",
       "        1.01018075e-04, 3.39862972e-04, 9.86851796e-03, 7.91510164e-03,\n",
       "        2.33355082e-02, 4.50029068e-04, 1.75704482e-03, 6.07732939e-02,\n",
       "        3.65556669e-03, 1.72036017e-03, 1.47413746e-03, 1.25083648e-02,\n",
       "        9.54375442e-02, 3.61750423e-04, 7.55073078e-03, 1.67281456e-01,\n",
       "        1.82731560e-03, 4.83217624e-03, 1.37942215e-02, 4.68492217e-02],\n",
       "       [7.27015013e-03, 3.36237111e-02, 5.24296952e-04, 1.41035943e-03,\n",
       "        6.80821643e-03, 9.82720704e-03, 7.11104187e-03, 2.64039698e-03,\n",
       "        5.00248283e-03, 1.52218422e-03, 1.39821964e-03, 2.03663409e-03,\n",
       "        1.02501959e-03, 8.41291782e-03, 3.60356105e-02, 5.98689861e-04,\n",
       "        1.28875055e-02, 4.93728066e-03, 4.04574435e-04, 2.91651899e-03,\n",
       "        1.03924263e-02, 5.65244057e-03, 1.93489159e-02, 3.17988116e-03,\n",
       "        6.66090247e-03, 3.64841710e-02, 3.65055154e-03, 7.42546876e-03,\n",
       "        5.63701448e-04, 5.82955302e-04, 1.99088741e-02, 1.40961459e-03,\n",
       "        9.79469137e-04, 1.53532490e-02, 1.75474719e-02, 8.09108222e-03,\n",
       "        8.07446981e-03, 1.05577372e-03, 7.83193311e-03, 1.08880606e-02,\n",
       "        6.81244006e-04, 2.08450086e-03, 2.39543704e-03, 7.51422218e-03,\n",
       "        1.47163772e-03, 1.29447501e-03, 3.10637400e-03, 9.21083109e-04,\n",
       "        6.63946821e-04, 3.63637810e-04, 2.36453239e-03, 1.01260109e-02,\n",
       "        3.39473404e-03, 3.36721795e-03, 3.51718066e-03, 2.06290743e-02,\n",
       "        1.14086045e-02, 5.67353633e-04, 1.79209734e-03, 4.46906915e-02,\n",
       "        8.89524611e-04, 4.27280280e-03, 5.56596158e-03, 1.14864369e-03,\n",
       "        6.10687184e-03, 3.89348263e-03, 1.09163343e-02, 4.30369422e-03,\n",
       "        5.18737769e-04, 4.08795894e-05, 8.62508656e-04, 1.27736840e-02,\n",
       "        2.06699882e-02, 2.75180485e-03, 2.40199248e-04, 2.25197287e-02,\n",
       "        3.22558191e-03, 1.06181175e-03, 4.97346648e-03, 2.64906520e-03,\n",
       "        1.67487106e-04, 1.25134618e-03, 1.32129030e-02, 7.99344673e-03,\n",
       "        4.17328302e-02, 6.43676598e-04, 1.43014065e-03, 3.71547090e-02,\n",
       "        3.90321159e-03, 1.57328485e-03, 4.25390518e-03, 2.09454300e-02,\n",
       "        8.84455877e-02, 6.63101371e-04, 6.18625052e-03, 1.64464012e-01,\n",
       "        2.26165697e-03, 4.25811528e-03, 1.06912752e-02, 2.55543714e-02],\n",
       "       [8.66215507e-03, 3.41771140e-02, 2.40718223e-04, 9.61120789e-04,\n",
       "        7.34680054e-03, 1.25987809e-02, 8.18670021e-03, 1.05208798e-02,\n",
       "        4.75583165e-03, 2.99636461e-03, 1.04563956e-03, 8.21650159e-04,\n",
       "        2.65663051e-03, 1.33410364e-02, 1.66267141e-02, 3.42926284e-04,\n",
       "        8.27996567e-03, 3.65630288e-03, 2.50037500e-04, 2.87266743e-03,\n",
       "        5.63071257e-03, 5.99735523e-03, 7.63752837e-03, 1.64809411e-03,\n",
       "        7.17263150e-03, 3.20681130e-02, 1.64464143e-03, 3.38458174e-03,\n",
       "        1.67366220e-03, 1.61360058e-04, 1.24564538e-02, 8.07878283e-04,\n",
       "        2.99742049e-04, 2.12359684e-02, 1.21635096e-02, 9.73117575e-03,\n",
       "        3.83542118e-03, 1.92571690e-03, 5.30901518e-03, 2.51448457e-02,\n",
       "        6.15964280e-04, 2.59572595e-03, 2.28866144e-03, 9.54519623e-03,\n",
       "        1.69542609e-03, 9.59522838e-04, 2.05996275e-03, 8.94789579e-04,\n",
       "        2.58884500e-04, 3.13693863e-04, 2.16406833e-03, 1.30538990e-02,\n",
       "        2.71194031e-03, 2.51403881e-03, 2.17100783e-03, 6.08551152e-03,\n",
       "        8.08500308e-03, 4.24903426e-04, 7.22686461e-04, 1.60604837e-02,\n",
       "        1.85798369e-03, 6.86433207e-03, 9.29182918e-03, 1.09183279e-03,\n",
       "        1.20268898e-02, 2.18163747e-03, 2.08979669e-02, 3.79765615e-03,\n",
       "        2.06908785e-04, 1.12555499e-05, 1.07482442e-03, 2.06164938e-02,\n",
       "        1.06688127e-01, 2.30794987e-03, 6.57874060e-04, 1.93849192e-02,\n",
       "        2.90112393e-03, 1.29433852e-03, 4.32125494e-03, 3.43554934e-03,\n",
       "        1.45874532e-04, 6.33548189e-04, 6.33508799e-03, 6.20225097e-03,\n",
       "        6.39397042e-02, 4.28435812e-04, 1.83259293e-03, 5.29333399e-02,\n",
       "        3.91782371e-03, 1.61246321e-03, 5.44069831e-03, 8.68759266e-03,\n",
       "        5.37113085e-02, 4.75615218e-04, 7.50354670e-03, 1.36304807e-01,\n",
       "        1.11228313e-03, 1.29815506e-02, 1.64015074e-02, 2.29994079e-02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear layer and softmax\n",
    "output_probabilities = linear_and_softmax(attention_output)\n",
    "output_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([84, 29, 95, 95, 95], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting the indices with the highest probabilities\n",
    "output_indices = np.argmax(output_probabilities, axis=-1)\n",
    "output_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion  \n",
    "\n",
    "In this article, we explored the fundamentals of a Transformer model in a practical way, implementing key components such as the scaled dot-product attention mechanism, the embedding layer, and the combination of linear and softmax layers. This hands-on approach complements the previously discussed theory, helping to solidify understanding of the components that make Transformers so powerful and versatile.  \n",
    "\n",
    "Throughout the process, we built a functional pipeline capable of processing input sequences, applying attention to focus on relevant parts of the data, and generating predictive outputs based on probabilities. This implementation serves as a starting point for understanding how Transformers operate internally and how they can be adapted for more complex tasks, such as machine translation, sentiment analysis, and text generation.  \n",
    "\n",
    "Transformers remain one of the most impactful architectures in modern artificial intelligence, and understanding them deeply is essential for anyone looking to work with state-of-the-art models. Now that you have a solid foundation, I recommend exploring more advanced implementations, such as multi-head attention layers, masking mechanisms for context control, and training on real-world datasets.  \n",
    "\n",
    "Continuous learning and practice are key to mastering this technology. I hope this article has been helpful and inspiring for your journey! 🚀  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
